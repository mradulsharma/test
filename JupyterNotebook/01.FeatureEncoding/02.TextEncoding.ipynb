{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Encoding \n",
    "![transform](TextEncoding.png)\n",
    "\n",
    "This jupyter notebook explains how text encoding can be done before feeding text data to train machine learning model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.> Lets load required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.> Define corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The sky is blue. The sun is bright today.']\n",
      "['The sun in the sky is bright. We can see the shining sun, the brighter sun.']\n"
     ]
    }
   ],
   "source": [
    "# Defining corpus => two seperate documents\n",
    "# Following is list of string, having only one element in list.\n",
    "document1 = [\"The sky is blue. The sun is bright today.\"]\n",
    "document2 = [\"The sun in the sky is bright. We can see the shining sun, the brighter sun.\"]\n",
    "\n",
    "print(document1)\n",
    "print(document2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.> Stemming : Words with the same root, but written grammatically differently, can be clubbed together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The sun in the sky is bright. We can see the shining sun, the bright sun.']\n"
     ]
    }
   ],
   "source": [
    "# In document2, we have word 'brighter' which is having same root/stem to word 'bright'.\n",
    "# Replace 'brighter' with 'bright'\n",
    "document2[0] = document2[0].replace(\"brighter\", \"bright\")\n",
    "\n",
    "print(document2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.> Text cleaning and tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'sky', 'is', 'blue', 'the', 'sun', 'is', 'bright', 'today']\n",
      "['the', 'sun', 'in', 'the', 'sky', 'is', 'bright', 'we', 'can', 'see', 'the', 'shining', 'sun', 'the', 'bright', 'sun']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Following is list of string, having each unique words from each document.\n",
    "all_tokens_document1 = sum([doc.lower().replace(',', '').replace('.', '').split() for doc in document1], [])\n",
    "all_tokens_document2 = sum([doc.lower().replace(',', '').replace('.', '').split() for doc in document2], [])\n",
    "\n",
    "print(all_tokens_document1)\n",
    "print(all_tokens_document2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.> Stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blue', 'sun', 'bright', 'sky', 'today'}\n",
      "{'see', 'we', 'sun', 'bright', 'sky', 'shining'}\n"
     ]
    }
   ],
   "source": [
    "# Define stopwords as list of words\n",
    "stopwords = ['a', 'the', 'i', 'me',  'is', 'to', 'then', 'what', 'are', 'for', 'my', 'as', 'can', 'and', 'in', 'of', 'am', 'it']\n",
    "\n",
    "# Subtract stopwords from each tokens.\n",
    "unique_token_document1 = set(all_tokens_document1) - set(stopwords)\n",
    "unique_token_document2 = set(all_tokens_document2) - set(stopwords)\n",
    "\n",
    "\n",
    "print(unique_token_document1)\n",
    "print(unique_token_document2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'see', 'we', 'sun', 'blue', 'bright', 'sky', 'today', 'shining'}\n"
     ]
    }
   ],
   "source": [
    "# Find unique set of tokens from entire corpus.\n",
    "unique_tokens_corpus = set(unique_token_document1).union(set(unique_token_document2))\n",
    "\n",
    "print(unique_tokens_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.> Making dictionary of unique words and word count appearing for each unique word in each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'see': 0, 'we': 0, 'sun': 0, 'blue': 0, 'bright': 0, 'sky': 0, 'today': 0, 'shining': 0}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary from unique tokens, and assign each key's value\n",
    "dictionary_of_doc1 = dict.fromkeys(unique_tokens_corpus, 0)     # dictionary_of_doc1 contents all tokens from corpus\n",
    "print(dictionary_of_doc1)\n",
    "print(type(dictionary_of_doc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blue', 'sun', 'bright', 'sky', 'today'}\n",
      "['The sky is blue. The sun is bright today.']\n",
      "{'see': 0, 'we': 0, 'sun': 1, 'blue': 1, 'bright': 1, 'sky': 1, 'today': 1, 'shining': 0}\n"
     ]
    }
   ],
   "source": [
    "# Count frequency of each word from first document, and update frequency to dictionary_of_doc1\n",
    "for token in all_tokens_document1:\n",
    "    if token in dictionary_of_doc1:\n",
    "        dictionary_of_doc1[token] += 1\n",
    "\n",
    "print(unique_token_document1)\n",
    "print(document1)\n",
    "print(dictionary_of_doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'see', 'we', 'sun', 'bright', 'sky', 'shining'}\n",
      "['The sun in the sky is bright. We can see the shining sun, the bright sun.']\n",
      "{'see': 1, 'we': 1, 'sun': 3, 'blue': 0, 'bright': 2, 'sky': 1, 'today': 0, 'shining': 1}\n"
     ]
    }
   ],
   "source": [
    "# Simillarly, count frequency of each word from second document, and update frequency to dictionary_of_doc2\n",
    "dictionary_of_doc2 = dict.fromkeys(unique_tokens_corpus, 0)     # dictionary_of_doc2 contents all tokens from corpus\n",
    "for token in all_tokens_document2:\n",
    "    if token in dictionary_of_doc2:\n",
    "        dictionary_of_doc2[token] += 1\n",
    "\n",
    "print(unique_token_document2)\n",
    "print(document2)\n",
    "print(dictionary_of_doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.> Calculate term frequency : TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count for document 1: 5.0\n",
      "\n",
      "dictionary_of_doc1 => {'see': 0, 'we': 0, 'sun': 1, 'blue': 1, 'bright': 1, 'sky': 1, 'today': 1, 'shining': 0}\n",
      "\n",
      "{'see': 0.0, 'we': 0.0, 'sun': 0.2, 'blue': 0.2, 'bright': 0.2, 'sky': 0.2, 'today': 0.2, 'shining': 0.0}\n"
     ]
    }
   ],
   "source": [
    "def calculate_term_frequency(doc_dictionary, lenght_of_doc_tokens):\n",
    "    tf = dict()\n",
    "    for key, value in doc_dictionary.items():\n",
    "        #print(f'key : {key} => value : {value}')           # Enable if want to see how internal function is working.\n",
    "        tf[key] = value / lenght_of_doc_tokens\n",
    "    return tf    \n",
    "\n",
    "token_count = float(len(unique_token_document1))            # unique_token_document1 contents only unique tokens from document 1\n",
    "print(\"Token count for document 1: \" + str(token_count) + \"\\n\")\n",
    "print(\"dictionary_of_doc1 => \" + str(dictionary_of_doc1) + \"\\n\")\n",
    "term_frequency_document1 = calculate_term_frequency(doc_dictionary=dictionary_of_doc1, lenght_of_doc_tokens=token_count)\n",
    "print(term_frequency_document1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count for document 2: 6.0\n",
      "\n",
      "dictionary_of_doc2 => {'see': 1, 'we': 1, 'sun': 3, 'blue': 0, 'bright': 2, 'sky': 1, 'today': 0, 'shining': 1}\n",
      "\n",
      "{'see': 0.16666666666666666, 'we': 0.16666666666666666, 'sun': 0.5, 'blue': 0.0, 'bright': 0.3333333333333333, 'sky': 0.16666666666666666, 'today': 0.0, 'shining': 0.16666666666666666}\n"
     ]
    }
   ],
   "source": [
    "token_count = float(len(unique_token_document2))            # unique_token_document2 contents only unique tokens from document 2\n",
    "print(\"Token count for document 2: \" + str(token_count) + \"\\n\")\n",
    "print(\"dictionary_of_doc2 => \" + str(dictionary_of_doc2) + \"\\n\")\n",
    "term_frequency_document2 = calculate_term_frequency(doc_dictionary=dictionary_of_doc2, lenght_of_doc_tokens=token_count)\n",
    "print(term_frequency_document2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.> Calculate inverse document frequency : IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "=> {'see': 1.0, 'we': 1.0, 'sun': 0.5945348918918356, 'blue': 1.0, 'bright': 0.5945348918918356, 'sky': 0.5945348918918356, 'today': 1.0, 'shining': 1.0}\n"
     ]
    }
   ],
   "source": [
    "def calculate_idf(*all_document_dictionary):\n",
    "    idf = dict()\n",
    "    number_of_dictionary = len(all_document_dictionary)\n",
    "\n",
    "    # Iterate over either of the document dictionary.\n",
    "    # Every document dictionary is having same set of keys but different values and we are only interested in keys,\n",
    "    #  to find its occurance if available in all documents.\n",
    "    # Keys in each dictionaries are : ['see', 'we', 'sun', 'blue', 'bright', 'sky', 'today', 'shining']\n",
    "    # We just want to know if key's value is > 0 in each dictonary to know count of documents key belongs to.\n",
    "    for key in all_document_dictionary[0].keys(): # taking first occurance of document dictionary with index zero (0)\n",
    "        df = 0\n",
    "        # Calculate document frequency for 'key'\n",
    "        for doc_dict in all_document_dictionary:            # Check availability of key in each document.\n",
    "            if key in doc_dict and doc_dict[key] > 0:       # If key exists in dictionary, and its value is > 0 then increase the document frequency.\n",
    "                df += 1\n",
    "\n",
    "        # Calculate IDF for 'key'\n",
    "        idf_of_term = math.log(number_of_dictionary / (1 + df)) + 1\n",
    "        idf[key] = idf_of_term\n",
    "\n",
    "    return idf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inverse_document_frequency_document = calculate_idf(dictionary_of_doc1, dictionary_of_doc2)\n",
    "\n",
    "print(\"\\n\\n\\n\\n=> \" + str(inverse_document_frequency_document))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.> Calculate TF-IDF = TF * IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to multiply both TF and IDF and store its value into dictionary and return.\n",
    "def calculate_tfidf(tf, idf):\n",
    "    tfidf = dict()\n",
    "    for token, count in tf.items():\n",
    "        tfidf[token] = count * idf[token]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blue', 'sun', 'bright', 'sky', 'today'}\n",
      "{'see', 'we', 'sun', 'bright', 'sky', 'shining'}\n"
     ]
    }
   ],
   "source": [
    "print(unique_token_document1)\n",
    "print(unique_token_document2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>see</th>\n",
       "      <th>we</th>\n",
       "      <th>sun</th>\n",
       "      <th>blue</th>\n",
       "      <th>bright</th>\n",
       "      <th>sky</th>\n",
       "      <th>today</th>\n",
       "      <th>shining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118907</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.118907</td>\n",
       "      <td>0.118907</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.297267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198178</td>\n",
       "      <td>0.099089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        see        we       sun  blue    bright       sky  today   shining\n",
       "0  0.000000  0.000000  0.118907   0.2  0.118907  0.118907    0.2  0.000000\n",
       "1  0.166667  0.166667  0.297267   0.0  0.198178  0.099089    0.0  0.166667"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TF-IDF for each unique tokens for both documents\n",
    "tfidf1 = calculate_tfidf(term_frequency_document1, inverse_document_frequency_document)\n",
    "tfidf2 = calculate_tfidf(term_frequency_document2, inverse_document_frequency_document)\n",
    "\n",
    "# Create a dataframe for all the calculated values\n",
    "tfidf_df = pd.DataFrame([tfidf1, tfidf2])\n",
    "tfidf_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
